{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "n3zmnHDJFcMF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from CSV\n",
        "data = pd.read_csv('/content/transformed_dataset.csv')"
      ],
      "metadata": {
        "id": "25DzdY3yFcIg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(subset=['Description'], inplace=True)  # Remove rows with missing descriptions\n"
      ],
      "metadata": {
        "id": "iQNiVyfWFcGc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate data and labels\n",
        "descriptions = data['Description'].values\n",
        "labels = data['Severity_Level'].values\n"
      ],
      "metadata": {
        "id": "xhlxHrf9FcD4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(descriptions)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)"
      ],
      "metadata": {
        "id": "nki_s_4dGZO1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(descriptions)\n",
        "max_sequence_length = max([len(seq) for seq in sequences])"
      ],
      "metadata": {
        "id": "E8HBwAQZGhu7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding sequences to the same length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n"
      ],
      "metadata": {
        "id": "xWtfsbzEGtEC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numpy array\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "gvWjqgLEGtAp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=16, input_length=max_sequence_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "Vh7NlzvfG4Q3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nTBLMuNqG-Mx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(padded_sequences, labels, epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6toOkxopHDZK",
        "outputId": "a9900fda-2a32-4759-9308-1d75c5ee808a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "247/247 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.0070\n",
            "Epoch 2/10\n",
            "247/247 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "247/247 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "247/247 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "247/247 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "247/247 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "247/247 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "247/247 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "247/247 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "247/247 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c77f9d252a0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(padded_sequences, labels, verbose=2)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-rLp-XTIQY5",
        "outputId": "92e474b1-8b26-49aa-ad7e-475305a6085c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 - 1s - loss: nan - accuracy: 0.0000e+00 - 601ms/epoch - 2ms/step\n",
            "Test accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory to save the model\n",
        "model_dir = '/content/mymodel.keras'\n",
        "\n",
        "# Save the model\n",
        "model.save(model_dir)"
      ],
      "metadata": {
        "id": "YY_9DbcMSlrV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory to save the model\n",
        "model_dir = '/content/trainedmodel.h5'\n",
        "\n",
        "# Save the model\n",
        "model.save(model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t8_Kjc0V0zc",
        "outputId": "aee037dc-0b6c-4be9-d950-03e23fc1f601"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import required modules\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "1jEsQ2FlWBBz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/mymodel.keras')\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbflb-t2WE42",
        "outputId": "5fe1a092-87ea-48cc-dd17-3ddab8273e59"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 367, 16)           272368    \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 16)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 272657 (1.04 MB)\n",
            "Trainable params: 272657 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model2 = tf.keras.models.load_model('/content/trainedmodel.h5')\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyYI00SfWQbY",
        "outputId": "d6f988ee-4578-4922-fa69-268e45a37d79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 367, 16)           272368    \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 16)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 272657 (1.04 MB)\n",
            "Trainable params: 272657 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}